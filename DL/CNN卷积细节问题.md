# CNN卷积细节问题
### 1.滤波器大小的选择
- 大部分卷积神经网络都会采用逐层递增（1⇒ 3 ⇒ 5 ⇒ 7）的方式。

- 每经过一次池化层，卷积层过滤器的深度都会乘以 2。

### 2.权值共享：减轻过拟合 & 降低计算量
一个卷积层（Wx+b ⇒ ReLU ⇒ maxpooling）可以有多个不同的卷积核，而每一个卷积核都对应一个滤波后映射出的新图像，同一个新图像中的每一个像素都来自完全相同的卷积核，这就是卷积核的权值共享。

那么为什么要共享卷积核的权值参数呢？

- 降低模型复杂度以减轻过拟合；

- 降低计算量；
### 3.待求参数的量化分析
考虑10^3 × 10^3的输入图像

1）全连接

隐藏神经元的数目为10^6时，则每一个输入像素与每一个隐藏神经元之间都有一个待学习的参数。

数目为10^6 × 10^6 = 10^12 个参数

2）卷积

卷积核的大小为10 × 10时，步长为10

数目为 10^3 × 10^3 × 10 × 10 = 10^8个参数

### 4.CNN 的卷积并没有执行“翻转”操作，而是与输入图像做滑动窗口“相关”计算；
